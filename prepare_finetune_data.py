# ======================================================================
# == prepare_finetune_data.py (–ï–î–ò–ù–´–ô –°–ö–†–ò–ü–¢ –ü–û–î–ì–û–¢–û–í–ö–ò –î–ê–ù–ù–´–•)
# ======================================================================
import json
from pathlib import Path
from mlx_lm.tuner.utils import save_dataset
import logging

# --- –ù–ê–°–¢–†–û–ô–ö–ò ---
SOURCE_FILE = Path("distillation_dataset.jsonl")
OUTPUT_DIR = Path("./packed_data_for_finetune")
# -----------------

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger(__name__)

def create_packed_dataset():
    logger.info("="*50)
    logger.info("--- –ó–∞–ø—É—Å–∫ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è ---")
    logger.info("="*50)

    if not SOURCE_FILE.exists():
        logger.error(f"‚ùå –ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª {SOURCE_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return

    OUTPUT_DIR.mkdir(exist_ok=True)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º "—Å—ã—Ä—ã–µ" –¥–∞–Ω–Ω—ã–µ
    with open(SOURCE_FILE, "r", encoding="utf-8") as f:
        data = [json.loads(line) for line in f]
    logger.info(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(data)} –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Ñ–∞–π–ª–µ.")
    
    reformatted_data = []
    for item in data:
        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ñ–æ—Ä–º–∞—Ç OpenAI –≤ –ø—Ä–æ—Å—Ç–æ–π –¥–∏–∞–ª–æ–≥
            user_content = item["messages"][0]["content"]
            assistant_content = item["messages"][1]["content"]
            reformatted_data.append({
                "conversations": [
                    {"from": "user", "value": user_content},
                    {"from": "assistant", "value": assistant_content},
                ]
            })
        except Exception:
            continue

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—É—é —É—Ç–∏–ª–∏—Ç—É –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
    # –û–Ω–∞ —Å–∞–º–∞ —Ä–∞–∑–æ–±—å–µ—Ç –¥–∞–Ω–Ω—ã–µ –Ω–∞ train/valid/test
    save_dataset(reformatted_data, OUTPUT_DIR)

    logger.info("\n" + "="*50)
    logger.info("üéâ –î–∞–Ω–Ω—ã–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –≥–æ—Ç–æ–≤—ã –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è!")
    logger.info(f"–£–ø–∞–∫–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –ø–∞–ø–∫—É: {OUTPUT_DIR.resolve()}")
    logger.info("="*50)

if __name__ == "__main__":
    create_packed_dataset()