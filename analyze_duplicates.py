#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ –∫–æ–¥–µ TradingBot
"""

import os
import hashlib
import json
from pathlib import Path
from collections import defaultdict
import difflib

def get_file_hash(filepath):
    """–í—ã—á–∏—Å–ª—è–µ—Ç MD5 —Ö–µ—à —Ñ–∞–π–ª–∞"""
    hash_md5 = hashlib.md5()
    try:
        with open(filepath, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {filepath}: {e}")
        return None

def get_file_info(filepath):
    """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ"""
    try:
        stat = os.stat(filepath)
        return {
            'size': stat.st_size,
            'mtime': stat.st_mtime,
            'path': str(filepath)
        }
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ñ–∞–π–ª–µ {filepath}: {e}")
        return None

def find_duplicates_by_hash(directory):
    """–ù–∞—Ö–æ–¥–∏—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ —Ö–µ—à—É —Ñ–∞–π–ª–æ–≤"""
    hash_groups = defaultdict(list)
    
    for root, dirs, files in os.walk(directory):
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º .history –∏ –¥—Ä—É–≥–∏–µ —Å–ª—É–∂–µ–±–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['__pycache__', 'node_modules']]
        
        for file in files:
            if file.endswith('.py'):
                filepath = Path(root) / file
                file_hash = get_file_hash(filepath)
                if file_hash:
                    hash_groups[file_hash].append(filepath)
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –≥—Ä—É–ø–ø—ã —Å –¥—É–±–ª–∏–∫–∞—Ç–∞–º–∏
    duplicates = {hash_val: files for hash_val, files in hash_groups.items() if len(files) > 1}
    return duplicates

def find_similar_files(directory, similarity_threshold=0.8):
    """–ù–∞—Ö–æ–¥–∏—Ç —Ñ–∞–π–ª—ã —Å –ø–æ—Ö–æ–∂–∏–º —Å–æ–¥–µ—Ä–∂–∏–º—ã–º"""
    py_files = []
    
    for root, dirs, files in os.walk(directory):
        dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['__pycache__', 'node_modules']]
        
        for file in files:
            if file.endswith('.py'):
                filepath = Path(root) / file
                py_files.append(filepath)
    
    similar_groups = []
    
    for i, file1 in enumerate(py_files):
        try:
            with open(file1, 'r', encoding='utf-8', errors='ignore') as f:
                content1 = f.read()
        except Exception:
            continue
            
        for file2 in py_files[i+1:]:
            try:
                with open(file2, 'r', encoding='utf-8', errors='ignore') as f:
                    content2 = f.read()
            except Exception:
                continue
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å
            similarity = difflib.SequenceMatcher(None, content1, content2).ratio()
            
            if similarity >= similarity_threshold:
                similar_groups.append({
                    'file1': str(file1),
                    'file2': str(file2),
                    'similarity': similarity
                })
    
    return similar_groups

def analyze_multiuserbot_files(directory):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∞–π–ª—ã MultiuserBot*"""
    multiuserbot_files = []
    
    for root, dirs, files in os.walk(directory):
        dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['__pycache__', 'node_modules']]
        
        for file in files:
            if file.startswith('MultiuserBot') and file.endswith('.py'):
                filepath = Path(root) / file
                file_info = get_file_info(filepath)
                if file_info:
                    multiuserbot_files.append(file_info)
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ä–∞–∑–º–µ—Ä—É
    size_groups = defaultdict(list)
    for file_info in multiuserbot_files:
        size_groups[file_info['size']].append(file_info)
    
    return multiuserbot_files, size_groups

def main():
    print("üîç –ê–Ω–∞–ª–∏–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ –∫–æ–¥–µ TradingBot")
    print("=" * 50)
    
    current_dir = Path.cwd()
    
    # 1. –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–æ–≤ MultiuserBot*
    print("\n1. –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–æ–≤ MultiuserBot*:")
    multiuserbot_files, size_groups = analyze_multiuserbot_files(current_dir)
    
    print(f"   –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(multiuserbot_files)}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≥—Ä—É–ø–ø—ã –ø–æ —Ä–∞–∑–º–µ—Ä—É
    for size, files in size_groups.items():
        if len(files) > 1:
            print(f"\n   –ì—Ä—É–ø–ø–∞ —Ñ–∞–π–ª–æ–≤ —Ä–∞–∑–º–µ—Ä–æ–º {size} –±–∞–π—Ç ({len(files)} —Ñ–∞–π–ª–æ–≤):")
            for file_info in files:
                print(f"     - {file_info['path']}")
    
    # 2. –ü–æ–∏—Å–∫ —Ç–æ—á–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ —Ö–µ—à—É
    print("\n2. –ü–æ–∏—Å–∫ —Ç–æ—á–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤:")
    duplicates = find_duplicates_by_hash(current_dir)
    
    if duplicates:
        print(f"   –ù–∞–π–¥–µ–Ω–æ –≥—Ä—É–ø–ø –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {len(duplicates)}")
        total_duplicate_files = sum(len(files) for files in duplicates.values())
        print(f"   –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {total_duplicate_files}")
        
        for file_hash, files in list(duplicates.items())[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 –≥—Ä—É–ø–ø
            print(f"\n   –ì—Ä—É–ø–ø–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ (—Ö–µ—à: {file_hash[:8]}...):")
            for filepath in files:
                print(f"     - {filepath}")
    else:
        print("   –¢–æ—á–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    # 3. –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Ñ–∞–π–ª–æ–≤
    print("\n3. –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Ñ–∞–π–ª–æ–≤ (—Å—Ö–æ–∂–µ—Å—Ç—å >= 80%):")
    similar_files = find_similar_files(current_dir, similarity_threshold=0.8)
    
    if similar_files:
        print(f"   –ù–∞–π–¥–µ–Ω–æ –ø–∞—Ä –ø–æ—Ö–æ–∂–∏—Ö —Ñ–∞–π–ª–æ–≤: {len(similar_files)}")
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ—Ö–æ–∂–∏–µ —Ñ–∞–π–ª—ã
        similarity_groups = defaultdict(list)
        for pair in similar_files:
            similarity_groups[round(pair['similarity'], 2)].append(pair)
        
        for similarity in sorted(similarity_groups.keys(), reverse=True):
            pairs = similarity_groups[similarity]
            print(f"\n   –§–∞–π–ª—ã —Å–æ —Å—Ö–æ–∂–µ—Å—Ç—å—é {similarity*100:.0f}% ({len(pairs)} –ø–∞—Ä):")
            for pair in pairs[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 –ø–∞—Ä—ã
                print(f"     - {pair['file1']}")
                print(f"       {pair['file2']}")
                print(f"       –°—Ö–æ–∂–µ—Å—Ç—å: {pair['similarity']*100:.1f}%")
                print()
    else:
        print("   –ü–æ—Ö–æ–∂–∏—Ö —Ñ–∞–π–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    # 4. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ä–∞–∑–º–µ—Ä–∞–º
    print("\n4. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ä–∞–∑–º–µ—Ä–∞–º —Ñ–∞–π–ª–æ–≤:")
    sizes = [f['size'] for f in multiuserbot_files]
    if sizes:
        total_size = sum(sizes)
        avg_size = total_size / len(sizes)
        print(f"   –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤: {total_size / 1024:.1f} KB")
        print(f"   –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {avg_size / 1024:.1f} KB")
        print(f"   –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {min(sizes) / 1024:.1f} KB")
        print(f"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {max(sizes) / 1024:.1f} KB")
    
    # 5. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ—á–∏—Å—Ç–∫–µ
    print("\n5. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ—á–∏—Å—Ç–∫–µ:")
    if duplicates:
        print("   ‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω—ã —Ç–æ—á–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã - –º–æ–∂–Ω–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ —É–¥–∞–ª–∏—Ç—å")
        print("   üí° –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ—Å—Ç–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ñ–∞–π–ª –∏–∑ –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
    
    if similar_files:
        print("   ‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω—ã –ø–æ—Ö–æ–∂–∏–µ —Ñ–∞–π–ª—ã - —Ç—Ä–µ–±—É–µ—Ç—Å—è —Ä—É—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞")
        print("   üí° –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Å—Ä–∞–≤–Ω–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏ –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å")
    
    print(f"\n   üìÅ –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ MultiuserBot*: {len(multiuserbot_files)}")
    print("   üóëÔ∏è  –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Å—Ç–∏ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ –∏ —É–¥–∞–ª–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã")

if __name__ == "__main__":
    main()





























